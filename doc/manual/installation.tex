All the underlying installation instructions assume a Linux operating system. We assume standard tools and libraries like CMake, compilers- (C, C++ and Fortran), and MPI libraries are pre-installed. Most high-performance computers would have the latest version of these libraries in the default environment. However, in many cases you would have to use \href{http://modules.sourceforge.net/}{Environment Modules} to set the correct environment variables for compilers-(C, C++ and Fortran), MPI libraries, and compilation tools like \href{http://www.cmake.org/}{CMake}. For example, on one of the high-performance computers we develop and test the \dftfe{} code, we use the following commands to set the desired environment variables
\begin{verbatim}
$ module load cmake
$ module load intel/18.0.1
$ module load openmpi/3.0.0/intel/18.0.1
\end{verbatim}
We strongly recommend using the latest stable version of compilers-(C, C++ and Fortran), and MPI libraries available on your high-performance computer. {\bf Our experience shows that Intel compilers provide the best performance}. Furthermore, for the installations which use \href{http://www.cmake.org/}{CMake}, version 2.8.12 or later is required.   

\subsection{Compiling and installing external libraries}
\dftfe{} is primarily based on the open source finite element library \href{http://www.dealii.org/}{deal.II}, through which external dependencies
on \href{http://p4est.org/}{p4est}, \href{https://www.mcs.anl.gov/petsc/}{PETSc}, \href{http://slepc.upv.es/}{SLEPc}, and \href{http://www.netlib.org/scalapack/}{ScaLAPACK} are set. ScaLAPACK is an optional requirement, but strongly recommended for large problem sizes with 5000 electrons or more. The other required external libraries, which are
not interfaced via deal.II are \href{http://www.alglib.net/}{ALGLIB}, \href{http://www.tddft.org/programs/libxc/}{Libxc}, \href{https://atztogo.github.io/spglib/}{spglib}, and \href{http://www.xmlsoft.org/}{Libxml2}. Some of the above libraries (PETSc, SLEPc, ScaLAPACK, and Libxml2) might already be installed on most high-performance computers.

Below, we give brief installation and/or linking instructions for each of the above libraries.
\subsubsection{Instructions for ALGLIB, Libxc, spglib, and Libxml2}
\begin{enumerate}
	\item   {\bf ALGLIB}: Used by \dftfe{} for spline fitting for various radial data. Download the current release of the Alglib free C++ edition from \url{http://www.alglib.net/download.php}. After downloading and unpacking, go to \verb|cpp/src|, and create a shared library using a C++ compiler. For example, using Intel compiler do
\begin{verbatim}
$ icpc -c -fPIC -O3 *.cpp
$ icpc *.o -shared -o libAlglib.so
\end{verbatim}
\item {\bf Libxc}: Used by \dftfe{} for exchange-correlation functionals. Download the current release from \url{http://www.tddft.org/programs/libxc/download/}, and follow the recommended installation procedure (using \verb|./configure|) described in \url{http://www.tddft.org/programs/libxc/installation/}.

\item {\bf spglib}: Used by \dftfe{} to find crystal symmetries. To install spglib, first obtain the development version of spglib from their github repository by
\begin{verbatim}
$ git clone https://github.com/atztogo/spglib.git	
\end{verbatim}	
and next follow the ``Compiling using cmake'' installation procedure described in \url{https://atztogo.github.io/spglib/install.html}.   	

\item {\bf Libxml2}: Libxml2 is used by \dftfe{} to read \verb|.xml| files. Most likely, Libxml2 might be already installed in the high-performance computer you are working with. It is usually installed in the default locations like \verb|/usr/lib64| (library path) and \verb|/usr/include/libxml2| (include path). Libxml2 can also be installed by doing
\begin{verbatim}
$ git clone git://git.gnome.org/libxml2	
\end{verbatim}
and following the installation instructions in the README.
\end{enumerate}

\subsubsection{Instructions for deal.II's dependencies-- p4est, PETSc, SLEPc, and ScaLAPACK}
\begin{enumerate}
	\item   {\bf p4est}: This library is used by deal.II to create and distribute finite-element meshes across multiple processors. Download the current release tarball of p4est from \url{http://www.p4est.org/}. Also download the script-- \href{https://github.com/dftfeDevelopers/dftfe/raw/manual/p4est-setup.sh}{p4est-setup.sh}, to automatically compile and install a debug and optimized version of p4est. To install using the script, do
\begin{verbatim}
$ chmod u+x p4est-setup.sh
$ ./p4est-setup.sh p4est-x-y-z.tar.gz p4est_install_dir_path
\end{verbatim}

	\item {\bf PETSc}: PETSc is a parallel linear algebra library. \dftfe{} needs two variants of the PETSc installation- one with real scalar type and the another with complex scalar type. Also both the installation variants must have 64-bit indices and optimized mode enabled during the installation. To install PETSc, first download the current release tarball from \url{https://www.mcs.anl.gov/petsc/download/index.html}, unpack it, and follow the installation instructions in \url{https://www.mcs.anl.gov/petsc/documentation/installation.html}. 
	
Below, we show an example installation for the real scalar type variant. 
This example should be used only as a reference.
\begin{verbatim}
$ ./configure --prefix=petsc_install_dir_path --with-debugging=no 
              --with-64-bit-indices=true --with-cc=c_compiler
              --with-cxx=c++_compiler --with-fc=fortran_compiler
              --with-blas-lapack-lib=(optimized BLAS-LAPACK library path) 
              CFLAGS=c_compilter_flags CXXFLAGS=c++_compiler_flags
	              FFLAGS=fortran_compiler_flags

$ make PETSC_DIR=prompted by PETSc 
       PETSC_ARCH=prompted by PETSc

$ make PETSC_DIR=prompted by PETSc 
       PETSC_ARCH=prompted by PETSc
       install
\end{verbatim}
For the complex installation variant, the only change is adding  \verb|--with-scalar-type=complex| to the configuration step above (\verb|./configure|).

Please notice that we have used place holders for values of some of the above configuration flags. You have to use the correct values specific to the compilers and MPI libraries you are working with. Also make sure to follow compiling recommendations for the high-performance computer you are compiling on. For example, if using Intel compilers and Intel MKL for BLAS-LAPACK, it is {\bf very important} to use \href{https://software.intel.com/en-us/articles/intel-mkl-link-line-advisor}{Intel MKL Link Line Advisor} to set the appropriate path for ``\verb|--with-blas-lapack-lib=|''. It can be something like
\begin{verbatim}
  --with-blas-lapack-lib="-Wl,--start-group 
  ${MKLROOT}/lib/intel64/libmkl_intel_lp64.a 
  ${MKLROOT}/lib/intel64/libmkl_intel_thread.a 
  ${MKLROOT}/lib/intel64/libmkl_core.a -Wl,--end-group
  -liomp5 -lpthread -lm -ldl" 
\end{verbatim}

\item {\bf SLEPc}: The SLEPc library is built on top of PETSc, and it is used in DFT-FE for Gram-Schmidt Orthogonalization. To install SLEPc, first download the current release tarball from \url{http://slepc.upv.es/download/}, and then follow the installation procedure described in \url{http://slepc.upv.es/documentation/instal.htm}. {\bf Important: } SLEPc installation requires PETSc to be installed first. You also need to create two separate SLEPc installations- one for PETSc installed with \\\verb|--with-scalar-type=real|, and the second for PETSc installed with \verb|--with-scalar-type=complex|.

\item {\bf ScaLAPACK}: ScaLAPACK library is used by DFT-FE via deal.II for its parallel linear algebra routines involving dense matrices. ScaLAPACK is already installed in most high-performance computers. For example, in case of Intel MKL, linking to pre-installed ScaLAPACK libraries would be something like (obtained via \href{https://software.intel.com/en-us/articles/intel-mkl-link-line-advisor}{Intel MKL Link Line Advisor})
\begin{verbatim}
${MKLROOT}/lib/intel64/libmkl_scalapack_lp64.so
${MKLROOT}/lib/intel64/libmkl_blacs_intelmpi_lp64.so
\end{verbatim}
where \verb|$MKLROOT| points to the directory path for Intel MKL library. It is important to note that the second line above points to the BLACS library, which ScaLAPACK requires to be linked with, and the choice of the BLACS library depends upon the MPI library one is using. For instance, the above example is shown for Intel MPI library. For Open MPI library, the BLACS path would become something like
\begin{verbatim}
${MKLROOT}/lib/intel64/libmkl_blacs_openmpi_lp64.so
\end{verbatim}

{\bf Installing ScaLAPACK from scratch}\\
Do not use these instructions if you already have pre-installed ScaLAPACK libraries on you high-performance computer.
Download the current release version from \url{http://www.netlib.org/scalapack/#\_software}, and build a shared library (use \verb|BUILD_SHARED_LIBS=ON| and \verb|BUILD_STATIC_LIBS=OFF|  during the cmake configuration) installation of ScaLAPACK using cmake. BLACS library, which is required for linking to Intel MKL ScaLAPACK, is not required to be installed separately as it is compiled along with the ScaLAPACK library. Hence you just have to link to\\ \verb|/your_scalapack_installation_dir/lib/libscalapack.so| for using the ScaLAPACK library. For best performance, ScaLAPACK must be linked to optimized BLAS-LAPACK libraries by using\\ \verb|USE_OPTIMIZED_LAPACK_BLAS=ON|, and providing external paths to BLAS-LAPACK during the cmake configuration.   	
\end{enumerate}

\subsubsection{Instructions for deal.II}
Assuming the above dependencies (p4est, PETSc, SLEPc, and ScaLAPACK) are installed, we now briefly discuss the steps to compile and install deal.II library linked with the above dependencies. You need to install two variants of the deal.II library-- one variant linked with PETSc and SLEPc real scalar type installations, and the other variant linked with PETSc and SLEPc complex scalar type installations. 

\begin{enumerate}

\item Obtain the development version of deal.II library via
\begin{verbatim}
$ git clone -b workingBranch https://github.com/dftfeDevelopers/dealii.git
\end{verbatim}

\item In addition to C, C++ and Fortran compilers, MPI library, and CMake which were required to install the above dependencies, deal.II additionaly requires BOOST library. If not found externally, cmake will resort to the bundled BOOST that comes along with deal.II. Based on our experience, we recommend to use the bundled boost (enforced by unsetting/unloading external BOOST library environment paths) to avoid compilation issues.

\item
\begin{verbatim}
$ mkdir buildReal
$ cd buildReal
$ cmake -DCMAKE_INSTALL_PREFIX=dealii_petscReal_install_dir_path
        otherCmakeOptions ../deal.II
$ make install
\end{verbatim}
{\bf ``otherCmakeOptions'' must include} the following options
\begin{verbatim}
-DDEAL_II_WITH_MPI=ON -DDEAL_II_WITH_64BIT_INDICES=ON
-DP4EST_DIR=p4est_install_dir_path
-DDEAL_II_WITH_PETSC=ON -DPETSC_DIR=petscReal_install_dir_path 
-DDEAL_II_WITH_SLEPC=ON -DSLEPC_DIR=slepcReal_install_dir_path
\end{verbatim}
and LAPACK and ScaLAPACK link options (see below for example). 

\item Repeat above step for installing deal.II linked with PETSc and SLEPc complex scalar type. 
\end{enumerate}	
 For more information about installing deal.II library refer to \url{https://dealii.org/developer/readme.html}. We also provide here an example of deal.II installation, which we did on a high-performance computer (\href{https://www.tacc.utexas.edu/systems/stampede2}{STAMPEDE2}) using Intel compilers and Intel MPI library (CXX flags used below are specific to the architecture)
\begin{verbatim}
$ mkdir build
$ cd build
$ cmake -DCMAKE_C_COMPILER=mpicc -DCMAKE_CXX_COMPILER=mpicxx 
  -DCMAKE_Fortran_COMPILER=mpif90 -DDEAL_II_CXX_FLAGS_RELEASE=-xMIC-AVX512 
  -DDEAL_II_CXX_FLAGS_DEBUG=-xMIC-AVX512  -DDEAL_II_COMPONENT_EXAMPLES=OFF
  -DDEAL_II_WITH_MPI=ON -DDEAL_II_WITH_64BIT_INDICES=ON
  -DP4EST_DIR=p4est_install_dir_path
  -DDEAL_II_WITH_PETSC=ON 
  -DPETSC_DIR=petsc_install_dir_path
  -DDEAL_II_WITH_SLEPC=ON
  -DSLEPC_DIR=petsc_install_dir_path
  -DDEAL_II_WITH_LAPACK=ON
  -DLAPACK_DIR="${MKLROOT}/lib/intel64" -DLAPACK_FOUND=true
  -DLAPACK_LIBRARIES="${MKLROOT}/lib/intel64/libmkl_intel_lp64.so;
  ${MKLROOT}/lib/intel64/libmkl_core.so;${MKLROOT}/lib/intel64/libmkl_intel_thread.so" 
  -DLAPACK_LINKER_FLAGS="-liomp5 -lpthread -lm -ldl"
  -DSCALAPACK_DIR="${MKLROOT}/lib/intel64"
  -DSCALAPACK_LIBRARIES="${MKLROOT}/lib/intel64/libmkl_scalapack_lp64.so;
  ${MKLROOT}/lib/intel64/libmkl_blacs_intelmpi_lp64.so"
  -DCMAKE_INSTALL_PREFIX=dealii_install_dir_path
  ../dealii
$ make -j 8
$ make install
\end{verbatim}
The values for \verb|-DLAPACK_DIR|,\verb|-DLAPACK_LIBRARIES|, \verb|-DLAPACK_LINKER_FLAGS|,\verb|-DSCALAPACK_DIR|, and\\ \verb|-DSCALAPACK_LIBRARIES| were obtained with the help of \href{https://software.intel.com/en-us/articles/intel-mkl-link-line-advisor}{Intel MKL Link Line Advisor}. Note that in the above procedure one is installing the development version of deal.II library and this version is continuously updated by deal.II developers, which can sometimes lead to installation issues on certain compilers. If you face any issues during the installation procedure of deal.II development version as explained above, you may alternatively obtain the current release version of deal.II by downloading and unpacking the .tar.gz file from \url{https://www.dealii.org/download.html} and following the same procedure as above. If you still face installation issues, and/or if you have any questions about the deal.II installation, please contact the deal.II developers at \href{https://groups.google.com/d/forum/dealii}{deal.II mailing lists}.\\

{\bf Using AVX, AVX-512 instructions in deal.II:}\\
deal.II compilation will automatically try to pick the available vector instructions on the sytem like SSE2, AVX and AVX-512, and generate the following output message during compilation   
\begin{verbatim}
-- Performing Test DEAL_II_HAVE_SSE2
-- Performing Test DEAL_II_HAVE_SSE2 - Success/Failed
-- Performing Test DEAL_II_HAVE_AVX
-- Performing Test DEAL_II_HAVE_AVX - Success/Failed
-- Performing Test DEAL_II_HAVE_AVX512
-- Performing Test DEAL_II_HAVE_AVX512 - Success/Failed
-- Performing Test DEAL_II_HAVE_OPENMP_SIMD
-- Performing Test DEAL_II_HAVE_OPENMP_SIMD - Success/Failed
\end{verbatim}
``Success'', means deal.II was able to use the corresponding vector instructions, and ``Failed'' would mean otherwise. If deal.II is not able to pick an available vector instruction on your high-performance computer, please contact the deal.II developers at \href{https://groups.google.com/d/forum/dealii}{deal.II mailing lists} and/or contact your high-performance computer support for guidance on how to use the correct compiler flags for AVX or AVX-512. 

Ensuring that deal.II picks up AVX-512 is strongly recommended for obtaining maximum performance on the new Intel Xeon Phi (KNL) and Skylake processors, both of which support Intel AVX-512 instructions.

\subsubsection{Important generic instructions for deal.II and its dependencies}
\begin{itemize}
\item If using Intel MKL for BLAS-LAPACK library, it is {\bf very important} to use \href{https://software.intel.com/en-us/articles/intel-mkl-link-line-advisor}{Intel MKL Link Line Advisor} to set correctly link with BLAS-LAPACK library as needed in installations of PETSc, ScaLAPACK, and deal.II. To exploit performance benefit from threads, we recommend (strongly recommended for the new Intel Xeon Phi (KNL) and Skylane processors) linking to threaded versions of Intel MKL libraries by using the options ``threading layer'' and  ``OpenMP library'' in \href{https://software.intel.com/en-us/articles/intel-mkl-link-line-advisor}{Intel MKL Link Line Advisor}. 

\item \textcolor{red}{\bf CAUTION! It is  very important to ensure that deal.II and its dependencies (p4est, PETSc, SLEPc, and ScaLAPACK), are compiled with the same compilers, BLAS-LAPACK libraries (except for p4est), and MPI libraries to prevent deal.II compilation issues, occurence of run time crashes, and \dftfe{} performance degradation.}  
\end{itemize}

\subsection{Obtaining and Compiling \dftfe{}}
Assuming that you have already installed the above external dependencies, next follow the steps below to obtain and compile \dftfe{}.
\begin{enumerate}
\item Obtain the source code of the current release of \dftfe{} with all current patches using \href{https://git-scm.com/}{Git}:
\begin{verbatim}
$ git clone -b release https://github.com/dftfeDevelopers/dftfe.git
$ cd dftfe
\end{verbatim}
Do \verb|git pull| in the \verb|dftfe| directory any time to obtain new patches that have been added since your \verb|git clone| or last \verb|git pull|.
If you are not familiar with Git, you may download from the current release \href{https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FdftfeDevelopers%2Fdftfe%2Farchive%2Fv0.5.0-pre.tar.gz&sa=D&sntz=1&usg=AFQjCNGict_QL7ffoe1ccR3wpMV96SvVCw}{tarball}, but downloading via Git is recommended to avail new patches seamlessly. 

{\bf Obtaining previous releases:} (Skip this part if you are using the current release version)
\begin{enumerate}
\item
\begin{verbatim}
$ git clone https://github.com/dftfeDevelopers/dftfe.git 
$ cd dftfe
\end{verbatim}

\item To get the list of all release tags (current and previous releases) do
\begin{verbatim}
$ git tag -l
\end{verbatim}

\item
Choose the desired release tag name and do
\begin{verbatim}
$ git checkout tags/<tag_name> 
\end{verbatim}
\end{enumerate}
Alternatively, you could download the appropriate tarball from \href{https://github.com/dftfeDevelopers/dftfe/releases}{github-releases}.

\item Set paths to external libraries (deal.II, ALGLIB, Libxc, spglib, and Libxml2), compiler options, and compiler flags in \verb|setup.sh|, which is a script to compile \dftfe{} using cmake. For your reference, a few example \verb|setup.sh| scripts are provided in the \verb|/helpers| folder. 
	
Please make sure to set \verb|withIntelMkl=ON| in setup.sh if you have installed deal.II by linking with Intel MKL library, otherwise set it to \verb|OFF|. 

\item To compile \dftfe{} in release mode (the fast version), set \verb|optimizedFlag=1| in \verb|setup.sh| and do
\begin{verbatim}
$ ./setup.sh
\end{verbatim} 
If compilation is successful, a \verb|/build| directory will be created with the following executables:
\begin{verbatim}
/build/release/real/main
/build/release/complex/main
\end{verbatim}

\item
To compile \dftfe{} in debug mode (much slower but useful for debugging), set \verb|optimizedFlag=0| in \verb|setup.sh| and do
\begin{verbatim}
$ ./setup.sh
\end{verbatim}
which will create the following debug mode executables:
\begin{verbatim}
/build/debug/real/main
/build/debug/complex/main
\end{verbatim}
\end{enumerate}
